{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import preprocess as pp\n",
    "import util\n",
    "\n",
    "import xskillscore as xs\n",
    "from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n",
    "\n",
    "# Progress bar for dask stuff\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_varnames = [\"tas\", \"pr\", \"psl\"]\n",
    "timeslice = slice('1981', '2010')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load interim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = xr.open_zarr(\"../data/intermediate/era5\").load()\n",
    "obs[\"nino34\"] = obs[\"enso34\"].std(dim='time', skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_dict = {}\n",
    "ens_av_dict = {}\n",
    "ens_std_dict = {}\n",
    "for key in pp.all_mip_ids:\n",
    "    ens = xr.open_zarr(f\"../data/intermediate/{key}\").chunk({'lat': -1, 'lon':-1}).load()\n",
    "    ens_dict[key] = ens\n",
    "    ens_dict[key][\"nino34\"] = ens_dict[key][\"enso34\"].std(dim='time', skipna=True)\n",
    "        \n",
    "    if key==\"far\":\n",
    "        ens_dict[key] = ens_dict[key].drop([\"tas_clim\", \"pr_clim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, ens in ens_dict.items():\n",
    "    print(f\"Generation {key}: \"+str(len(ens.ensemble.values))+\" (\"+str(len(np.unique(ens.source_id.values)))+\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute magnitude of seasonal cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ens_dict.keys():\n",
    "    for dv in ens_dict[key].data_vars:\n",
    "        if '_clim' in dv:\n",
    "            clim = ens_dict[key][dv]\n",
    "            ens_dict[key][dv.split(\"_\")[0]+\"_season\"] = clim.sel(month=[6, 7, 8]).mean(dim='month') - clim.sel(month=[12, 1, 2]).mean(dim='month')\n",
    "            \n",
    "for dv in obs.data_vars:\n",
    "    if '_clim' in dv:\n",
    "        clim = obs[dv]\n",
    "        obs[dv.split(\"_\")[0]+\"_season\"] = clim.sel(month=[6, 7, 8]).mean(dim='month') - clim.sel(month=[12, 1, 2]).mean(dim='month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continental temperatures 20ÂºC higher than other ensemble members...\n",
    "ens_dict['cmip6'] = ens_dict['cmip6'].isel(ensemble = ens_dict['cmip6']['ensemble'] != 'NIMS-KMA-KACE-1-0-G-r3i1p1f1')\n",
    "\n",
    "# Units seem to be wrong... even after using the correction on the first ensemble member\n",
    "ens_dict['cmip6'] = ens_dict['cmip6'].isel(ensemble = ens_dict['cmip6']['ensemble'] != 'UA-MCM-UA-1-0-r1i1p1f2')\n",
    "\n",
    "# Negative precipitation...\n",
    "ens_dict['sar']['pr_mean'].loc[{'ensemble': 'HCCPR-HCCPR-01-r3i1p1f1'}] = np.nan\n",
    "\n",
    "#ens_dict['far'].loc[{'ensemble': 'UKTR-UKTR-r1i1p1f1'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = util.calc_area(obs.lat, obs.lon)\n",
    "\n",
    "skill_varnames = ['tas_trend', 'tas_mean', 'tas_season', 'pr_mean', 'pr_season', 'psl_mean', 'psl_season']\n",
    "\n",
    "skill_dict = {}\n",
    "skill_av_dict = {}\n",
    "skill_std_dict = {}\n",
    "\n",
    "for key, ens in tqdm(ens_dict.items()):\n",
    "    ens_tmp = ens.drop([var for var in list(ens.data_vars) if var not in skill_varnames]).drop_dims([\"month\", \"time\"])\n",
    "    obs_tmp = obs.drop([var for var in list(obs.data_vars) if var not in list(ens_tmp.data_vars)]).drop_dims([\"month\", \"time\"])\n",
    "    mae = xs.mae(\n",
    "        obs_tmp,\n",
    "        ens_tmp,\n",
    "        ['lat', 'lon'], weights=area\n",
    "    ).compute()\n",
    "    # mae['nino34'] = np.abs(ens['nino34'] - obs['nino34'])\n",
    "    rename_mae = dict([(v, v+\"_mae\") for v in obs_tmp.data_vars])\n",
    "    mae = mae.rename(rename_mae)\n",
    "    \n",
    "    rpearson = 1. - xr.concat([xs.pearson_r(obs_tmp, ens_tmp.sel(ensemble=e), dim=[\"lat\", \"lon\"], weights=area) for e in ens_tmp.ensemble.values], dim='ensemble')\n",
    "    rename_rpearson = dict([(v, v+\"_rpearson\") for v in obs_tmp.data_vars])\n",
    "    rpearson = rpearson.rename(rename_rpearson)\n",
    "    \n",
    "    skill = xr.merge([mae, rpearson])\n",
    "    skill_dict[key] = skill\n",
    "    skill_av_dict[key] = skill.groupby('source_id').mean(skipna=True)\n",
    "    skill_std_dict[key] = skill.groupby('source_id').std(skipna=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMIP6 median\n",
    "skill_med = skill_av_dict['cmip6'].median(dim='source_id', skipna=True).compute()\n",
    "skill_score_dict = {}\n",
    "skill_score_std_dict = {}\n",
    "\n",
    "for key in skill_av_dict.keys():\n",
    "    skill_score_dict[key] = (skill_av_dict[key]/skill_med)\n",
    "    skill_score_std_dict[key] = (skill_std_dict[key]/skill_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_weights = {\n",
    "    'tas_mean': 1./9.,\n",
    "    'pr_mean': 1./9.,\n",
    "    'psl_mean': 1./9.,\n",
    "    'tas_season': 1./9.,\n",
    "    'pr_season': 1./9.,\n",
    "    'psl_season': 1./9.,\n",
    "    'tas_trend': 1./3.,\n",
    "}\n",
    "\n",
    "performance_weights = dict([(key + \"_mae\", item/2.) for key, item in prefix_weights.items()] + [(key + \"_rpearson\", item/2.) for key, item in prefix_weights.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, ss in skill_score_dict.items():\n",
    "    da = xr.concat([ss[d] for d in ss.data_vars], dim='metric')\n",
    "    da.name = \"performance\"\n",
    "    da = da.assign_coords({'metric': [d for d in ss.data_vars]})\n",
    "    da['weights'] = xr.DataArray([performance_weights[d] for d in ss.data_vars], dims='metric')\n",
    "    da['performance'] = (da * da['weights']).sum(dim='metric') / ((~np.isnan(da)) * da['weights']).sum(dim='metric')\n",
    "    \n",
    "    skill_score_dict[key]['performance'] = da['performance']\n",
    "    skill_score_std_dict[key]['performance'] = da['performance']*0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skill metrics over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mip_year_dict = {'far': 1990,\n",
    "                 'sar': 1996,\n",
    "                 'tar': 2000,\n",
    "                 'cmip3': 2005,\n",
    "                 'cmip5': 2013,\n",
    "                 'cmip6': 2019}\n",
    "\n",
    "mip_col = {'far': 'C5',\n",
    "           'sar': 'C4',\n",
    "           'tar': 'C3',\n",
    "           'cmip3': 'C2',\n",
    "           'cmip5': 'C1',\n",
    "           'cmip6': 'C0'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Mean absolute error for precipitation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_score_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_key = 'pr_mean_mae'\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "for key, ens in ens_dict.items():\n",
    "    \n",
    "    data = skill_score_dict[key][var_key]\n",
    "    data_err = skill_score_std_dict[key][var_key]\n",
    "    ax.errorbar(\n",
    "        data,\n",
    "        mip_year_dict[key]*np.ones_like(data) + 4*(np.random.rand(*data.shape)-0.5),\n",
    "        xerr=data_err,\n",
    "        linewidth=0., elinewidth=1., ecolor='k',\n",
    "        marker=\"o\", markersize=10, alpha=0.5, color=mip_col[key], zorder=1\n",
    "    )\n",
    "\n",
    "    data = skill_score_dict[key][var_key].median(skipna=True)\n",
    "    ax.plot(data, mip_year_dict[key]*np.ones_like(data),\n",
    "         marker='s', markersize=12, color=\"k\", markeredgecolor='k', zorder=2)\n",
    "    \n",
    "ax.set_title(\"Mean precipitation bias\")\n",
    "\n",
    "ax.set_ylim([1985,2025])\n",
    "ax.set_xlim([0.5, 3.0])\n",
    "ax.set_ylabel('publication date')\n",
    "ax.set_xlabel('normalized model absolute error')\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/model_performance_pr-mae_example.png\",bbox_inches='tight',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_key = 'performance'\n",
    "\n",
    "medians = []\n",
    "years = []\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "for key, ens in ens_dict.items():\n",
    "    \n",
    "    data = skill_score_dict[key][var_key]\n",
    "    data_err = skill_score_std_dict[key][var_key]\n",
    "    ax.errorbar(\n",
    "        data,\n",
    "        mip_year_dict[key]*np.ones_like(data) + 4*(np.random.rand(*data.shape)-0.5),\n",
    "        xerr=data_err,\n",
    "        linewidth=0., elinewidth=1., ecolor='k',\n",
    "        marker=\"o\", markersize=10, alpha=0.5, color=mip_col[key], zorder=1\n",
    "    )\n",
    "\n",
    "    data = skill_score_dict[key][var_key].median(skipna=True)\n",
    "    medians.append(data.values)\n",
    "    years.append(mip_year_dict[key])\n",
    "    ax.plot(data, mip_year_dict[key]*np.ones_like(data),\n",
    "         marker='s', markersize=12, color=\"k\", markeredgecolor='k', zorder=2)\n",
    "    \n",
    "    \n",
    "a, b = np.polyfit(years, medians, 1)\n",
    "x = np.arange(1985., 2100., 1.)\n",
    "#ax.plot(a*x + b, x, \"k--\")\n",
    "    \n",
    "ax.set_title(\"Overall performance\")\n",
    "\n",
    "ax.set_ylim([1985,2025])\n",
    "ax.set_xlim([0., 2.5])\n",
    "ax.set_ylabel('publication date')\n",
    "ax.set_xlabel('normalized model performance index')\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/model_performance_nofit.png\",bbox_inches='tight',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_key = 'performance'\n",
    "\n",
    "medians = []\n",
    "years = []\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "for key, ens in ens_dict.items():\n",
    "    \n",
    "    data = skill_score_dict[key][var_key]\n",
    "    data_err = skill_score_std_dict[key][var_key]\n",
    "    ax.errorbar(\n",
    "        data,\n",
    "        mip_year_dict[key]*np.ones_like(data) + 4*(np.random.rand(*data.shape)-0.5),\n",
    "        xerr=data_err,\n",
    "        linewidth=0., elinewidth=1., ecolor='k',\n",
    "        marker=\"o\", markersize=10, alpha=0.5, color=mip_col[key], zorder=1\n",
    "    )\n",
    "\n",
    "    data = skill_score_dict[key][var_key].median(skipna=True)\n",
    "    medians.append(data.values)\n",
    "    years.append(mip_year_dict[key])\n",
    "    ax.plot(data, mip_year_dict[key]*np.ones_like(data),\n",
    "         marker='s', markersize=12, color=\"k\", markeredgecolor='k', zorder=2)\n",
    "    \n",
    "    \n",
    "a, b = np.polyfit(years, medians, 1)\n",
    "x = np.arange(1985., 2100., 1.)\n",
    "ax.plot(a*x + b, x, \"k--\")\n",
    "    \n",
    "ax.set_title(\"Overall performance\")\n",
    "\n",
    "ax.set_ylim([1985,2040])\n",
    "ax.set_xlim([0., 2.5])\n",
    "ax.set_ylabel('publication date')\n",
    "ax.set_xlabel('normalized model performance index')\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/model_performance.png\",bbox_inches='tight',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_key = 'performance'\n",
    "\n",
    "medians = []\n",
    "years = []\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "for key, ens in ens_dict.items():\n",
    "    \n",
    "    data = skill_score_dict[key][var_key]\n",
    "    data_err = skill_score_std_dict[key][var_key]\n",
    "    ax.errorbar(\n",
    "        data,\n",
    "        mip_year_dict[key]*np.ones_like(data) + 4*(np.random.rand(*data.shape)-0.5),\n",
    "        xerr=data_err,\n",
    "        linewidth=0., elinewidth=1., ecolor='k',\n",
    "        marker=\"o\", markersize=10, alpha=0.5, color=mip_col[key], zorder=1\n",
    "    )\n",
    "\n",
    "    data = skill_score_dict[key][var_key].median(skipna=True)\n",
    "    medians.append(data.values)\n",
    "    years.append(mip_year_dict[key])\n",
    "    ax.plot(data, mip_year_dict[key]*np.ones_like(data),\n",
    "         marker='s', markersize=12, color=\"k\", markeredgecolor='k', zorder=2)\n",
    "    \n",
    "    \n",
    "a, b = np.polyfit(years, medians, 1)\n",
    "x = np.arange(1985., 2100., 1.)\n",
    "ax.plot(a*x + b, x, \"k--\")\n",
    "ax.fill_between([0., 0.15], [1985, 1985], [2040, 2040], facecolor='r', alpha=0.2)\n",
    "ax.fill_between([0.15, 0.45], [1985, 1985], [2040, 2040], facecolor='grey', alpha=0.2)\n",
    "    \n",
    "ax.annotate(text=\"observational error (?)\", xy=(0.03, 2000.25), xycoords='data', rotation=90.)\n",
    "ax.annotate(text=\"internal variability (?)\", xy=(0.25, 2001), xycoords='data', rotation=90.)\n",
    "\n",
    "ax.set_title(\"Overall performance\")\n",
    "\n",
    "ax.set_ylim([1985,2040])\n",
    "ax.set_xlim([0., 2.5])\n",
    "ax.set_ylabel('publication date')\n",
    "ax.set_xlabel('normalized model performance index')\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/model_performance_uncertainty.png\",bbox_inches='tight',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(skill_score_dict[\"cmip6\"]),1,figsize=(8,60))\n",
    "\n",
    "for key, ens in ens_dict.items():\n",
    "    \n",
    "    subplot_count = 1\n",
    "    for idx, var_key in enumerate(skill_score_dict[\"cmip6\"].keys()):\n",
    "            \n",
    "        if var_key not in skill_score_dict[key].data_vars: continue\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        data = skill_score_dict[key][var_key]\n",
    "        data_err = skill_score_std_dict[key][var_key]\n",
    "        ax.errorbar(\n",
    "            data,\n",
    "            mip_year_dict[key]*np.ones_like(data) + 4*(np.random.rand(*data.shape)-0.5),\n",
    "            xerr=data_err,\n",
    "            linewidth=0., elinewidth=1., ecolor='k',\n",
    "            marker=\"o\", markersize=10, alpha=0.5, color=mip_col[key], zorder=1\n",
    "        )\n",
    "\n",
    "        data = skill_score_dict[key][var_key].median(skipna=True)\n",
    "        ax.plot(data, mip_year_dict[key]*np.ones_like(data),\n",
    "             marker='s', markersize=12, color=\"k\", markeredgecolor='k', zorder=2)\n",
    "        \n",
    "        subplot_count+=1\n",
    "        ax.set_title(var_key)\n",
    "\n",
    "for subplot_count, ax in enumerate(axes):\n",
    "\n",
    "    ax.set_ylim([1985,2025])\n",
    "    ax.set_xlim([0.5, 3.0])\n",
    "    ax.set_ylabel('publication date')\n",
    "    ax.set_xlabel('normalized model mean absolute error')\n",
    "    ax.grid(True)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/model_performance_over_time_fullscatter.png\",bbox_inches='tight',dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots below do not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_shape = {'tas':'s', 'pr':'o', 'psl':'d'}\n",
    "\n",
    "fig, axes = plt.subplots(len(var_shape),1,figsize=(8,30))\n",
    "\n",
    "for key, ens in ens_dict.items():\n",
    "    \n",
    "    subplot_count = 1\n",
    "    for idx, var_key in enumerate(var_shape.keys()):\n",
    "        \n",
    "        if var_key not in rpearson_skill_score_dict[key]: continue\n",
    "        \n",
    "        if var_key == 'tas':\n",
    "            ens_label = key\n",
    "        else:\n",
    "            ens_label = None\n",
    "            \n",
    "        ax = axes[idx]\n",
    "        \n",
    "        data = rpearson_skill_score_dict[key][var_key]\n",
    "        data_err = rpearson_std_skill_score_dict[key][var_key]\n",
    "        ax.errorbar(\n",
    "            data,\n",
    "            mip_year_dict[key]*np.ones_like(data) + 4*(np.random.rand(*data.shape)-0.5),\n",
    "            xerr=data_err,\n",
    "            linewidth=0., elinewidth=1., ecolor='k',\n",
    "            marker=var_shape[var_key], markersize=10, alpha=0.5, label=ens_label, color=mip_col[key], zorder=1\n",
    "        )\n",
    "\n",
    "        data = rpearson_skill_score_dict[key][var_key].median(skipna=True)\n",
    "        ax.plot(data, mip_year_dict[key]*np.ones_like(data),\n",
    "             marker='o', markersize=12, color=\"k\", markeredgecolor='k', zorder=2)\n",
    "        \n",
    "        subplot_count+=1\n",
    "        \n",
    "        ax.set_title(var_key+\" performance\")\n",
    "    \n",
    "#var_longname = ['near-surface air temperature', 'precipitation rate', 'sea level pressure']\n",
    "\n",
    "for subplot_count, ax in enumerate(axes):\n",
    "\n",
    "    ax.set_ylim([1985,2025])\n",
    "    ax.set_xlim([0, 2.5])\n",
    "    ax.set_ylabel('publication date')\n",
    "    ax.set_xlabel('normalized model mean absolute error')\n",
    "    ax.grid(True)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/model_rpearson_over_time_fullscatter.png\",bbox_inches='tight',dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_dict['cmip6']['tas_trend'].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_dict['cmip6'].ensemble.values[114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_dict['cmip6']['tas_trend'].sel(ensemble='E3SM-Project-E3SM-1-1-ECA-r1i1p1f1').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_dict['cmip6']['tas_mean'].sel(ensemble='E3SM-Project-E3SM-1-1-ECA-r1i1p1f1').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ens_dict['cmip6']['tas_mean'].sel(ensemble='E3SM-Project-E3SM-1-1-ECA-r1i1p1f1') - obs['tas_mean']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(plot_varnames),1,figsize=(8,12))\n",
    "\n",
    "ax=axes[0]\n",
    "ens_mean_label = \"ens-mean\"\n",
    "ax.plot([], [], 'k<', markersize=10, label=ens_mean_label)\n",
    "ax.plot([], [], 'k>', markersize=10, label='ens-median')\n",
    "\n",
    "ax.plot([], [], 'k', marker=var_shape['tas'], markersize=10, label='tas', linewidth=0.)\n",
    "ax.plot([], [], 'k', marker=var_shape['pr'], markersize=10, label='pr', linewidth=0.)\n",
    "ax.plot([], [], 'k', marker=var_shape['psl'], markersize=10, label='sfcWind', linewidth=0.)\n",
    "\n",
    "for key, ens in ens_dict.items():\n",
    "    \n",
    "    subplot_count = 1\n",
    "    for idx, var_key in enumerate(var_shape.keys()):\n",
    "        \n",
    "        if var_key not in mae_dict[key]: continue\n",
    "        \n",
    "        if var_key == 'tas':\n",
    "            ens_label = key\n",
    "        else:\n",
    "            ens_label = None\n",
    "            \n",
    "        ax = axes[idx]\n",
    "        \n",
    "        data = mae_skill_score_dict[key][var_key]\n",
    "        data = data[~np.isnan(data)]\n",
    "        \n",
    "        alpha=0.75\n",
    "        markersize=15.\n",
    "        if data.size > 10:\n",
    "            alpha=0.4\n",
    "            markersize=10\n",
    "            \n",
    "        ax.plot(\n",
    "            data,mip_year_dict[key]*np.ones_like(data),\n",
    "            linewidth=0, marker=\".\", markersize=markersize, alpha=alpha, color=\"C0\"\n",
    "        )\n",
    "        \n",
    "        if data.size > 10:\n",
    "            parts = ax.violinplot(\n",
    "                data[~np.isnan(data)],\n",
    "                positions=[mip_year_dict[key]],\n",
    "                widths = 5.,\n",
    "                vert=False, showextrema=False,\n",
    "            )\n",
    "\n",
    "            for pc in parts['bodies']:\n",
    "                pc.set_facecolor(\"C0\")\n",
    "                pc.set_edgecolor(\"k\")\n",
    "                pc.set_alpha(0.3)\n",
    "\n",
    "        subplot_count+=1\n",
    "    \n",
    "var_longname = ['near-surface air temperature', 'precipitation rate', 'sea level pressure']\n",
    "var_minlim = [0.0, 0.0, 0.0]\n",
    "var_maxlim = [3.5, 3.5, 3.5]\n",
    "for subplot_count, ax in enumerate(axes):\n",
    "\n",
    "    ax.set_ylim([1985,2025])\n",
    "    ax.set_xlim([var_minlim[subplot_count], var_maxlim[subplot_count]])\n",
    "    ax.set_ylabel('publication date')\n",
    "    ax.set_xlabel('normalized model mean absolute error')\n",
    "    if subplot_count == 0: ax.legend()\n",
    "    ax.set_title(var_longname[subplot_count]+' performance')\n",
    "    ax.grid(True)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/model_performance_over_time_violin.png\",bbox_inches='tight',dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mip = 'cmip6'\n",
    "percent_spread = (mae_dict[mip].groupby('source_id').max() - mae_dict[mip].groupby('source_id').min())/mae_dict[mip].groupby('source_id').mean(skipna=True).compute()\n",
    "for dv in percent_spread.data_vars:\n",
    "    percent_spread[dv].loc[percent_spread[dv]==0.] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(percent_spread['pr_mean'].values, \"o\", label='pr')\n",
    "plt.plot(percent_spread['tas_mean'].values, \"o\", label='tas')\n",
    "plt.plot(percent_spread['psl_mean'].values, \"o\", label='psl')\n",
    "plt.xticks(np.arange(0, len(percent_spread.source_id.values)), percent_spread.source_id.values, rotation=90)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = (ens_dict['sar'].sel(ensemble='HCCPR-HCCPR-01-r3i1p1f1')['pr_mean']).plot()\n",
    "#q.set_clim([0., 1.e-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = obs['pr_mean'].plot()\n",
    "q.set_clim([0., 1.e-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = ens_dict['sar'].sel(ensemble='HCCPR-HCCPR-01-r2i1p1f1')['pr_mean'].plot()\n",
    "q.set_clim([0., 1.e-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ens_dict['sar'].sel(ensemble='HCCPR-HCCPR-01-r2i1p1f1')['pr'] - ens_dict['sar'].sel(ensemble='HCCPR-HCCPR-01-r3i1p1f1')['pr']).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
