{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions for activated the Jupyter kernel for the `cmip6hack-multigen` conda environment\n",
    "\n",
    "In a Jupyterlab terminal, navigate to the `/cmip6hack-multigen/` folder and run the command:\n",
    "```bash\n",
    "source spinup_env.sh\n",
    "```\n",
    "which will create the `cmip6hack-multigen` conda environment and install it as a python kernel for jupyter.\n",
    "\n",
    "Then, switch the kernel (drop-down menu in the top right hand corner) to cmip6hack-multigen and restart the notebook.\n",
    "\n",
    "### Pre-processing climate model output in GCS\n",
    "\n",
    "This notebook uses [`intake-esm`](https://intake-esm.readthedocs.io/en/latest/) to ingest and organize climate model output from various model generations and resave their time-mean fields locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/cmip6hack-multigen/lib/python3.7/site-packages/ipykernel_launcher.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xskillscore as xs\n",
    "import xesmf as xe\n",
    "from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n",
    "import intake\n",
    "# util.py is in the local directory\n",
    "# it contains code that is common across project notebooks\n",
    "# or routines that are too extensive and might otherwise clutter\n",
    "# the notebook design\n",
    "import util\n",
    "import organization as org\n",
    "import qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = ['tas', 'pr', 'psl']\n",
    "time_slice = slice('1981', '2010')\n",
    "\n",
    "coarsen_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = org.get_ipcc_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mip_ids = org.all_mip_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3f727b77c043eaba238cecea45dd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " far tas\n",
      "\n",
      " far pr\n",
      "\n",
      " far psl\n",
      "\n",
      " sar tas\n",
      "\n",
      " sar pr\n",
      "\n",
      " sar psl\n",
      "\n",
      " tar tas\n",
      "\n",
      " tar pr\n",
      "\n",
      " tar psl\n",
      "\n",
      " cmip3 tas\n",
      "Weird time units breaks ds.sel(time=time_slice)\n",
      "\n",
      " cmip3 pr\n",
      "Weird time units breaks ds.sel(time=time_slice)\n",
      "\n",
      " cmip3 psl\n",
      "\n",
      " cmip5 tas\n",
      "\n",
      " cmip5 pr\n",
      "Weird time units breaks ds.sel(time=time_slice)\n",
      "\n",
      " cmip5 psl\n",
      "\n",
      " cmip6 tas\n",
      "\n",
      " cmip6 pr\n",
      "\n",
      " cmip6 psl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds_dict = {}\n",
    "for mip_id in tqdm(mip_ids):\n",
    "    ds_dict[mip_id] = {}\n",
    "    for varname in varnames:\n",
    "        print(mip_id, varname)\n",
    "        col = col_dict[mip_id]\n",
    "        cat = col.search(\n",
    "            experiment_id='historical',\n",
    "            variable_id=varname,\n",
    "            member_id='r1i1p1f1',# choose first ensemble member only (for now)\n",
    "            table_id='Amon'\n",
    "        )\n",
    "        \n",
    "        if cat.df.size == 0: continue\n",
    "\n",
    "        with util.HiddenPrints():\n",
    "            dset_dict = cat.to_dataset_dict(zarr_kwargs={'consolidated': True, 'decode_times': False})\n",
    "\n",
    "        ds_dict[mip_id][varname] = {}\n",
    "        for key, ds in dset_dict.items():            \n",
    "            # rename spatial dimensions if necessary\n",
    "            if ('longitude' in ds.dims) and ('latitude' in ds.dims):\n",
    "                ds = ds.rename({'longitude':'lon', 'latitude': 'lat'})\n",
    "            \n",
    "            ds = xr.decode_cf(ds) # Need this temporarily because setting 'decode_times': True appears broken\n",
    "            ds = ds.squeeze() # get rid of member_id (for now)\n",
    "            \n",
    "            # take long-term mean\n",
    "            try:\n",
    "                timeave = ds.sel(time=time_slice).mean(dim='time', keep_attrs=True)\n",
    "            except:\n",
    "                # A few cases of weird cftime stuff going on...\n",
    "                print(\"Weird time units breaks ds.sel(time=time_slice)\")\n",
    "                continue\n",
    "            \n",
    "            if mip_id != 'cmip6':\n",
    "                chunks = {'lat':timeave['lat'].size, 'lon':timeave['lon'].size}\n",
    "                timeave = timeave.chunk(chunks)\n",
    "            \n",
    "            with util.HiddenPrints():\n",
    "                ds_new = util.regrid_to_common(timeave[varname])\n",
    "                \n",
    "            ds_new.attrs.update(timeave.attrs)\n",
    "            ds_new = qc.quality_control(ds_new, varname, key, mip_id)\n",
    "            \n",
    "            ds_new.attrs['name'] = \"-\".join(key.split(\".\")[1:3])\n",
    "            \n",
    "            for coord in ds_new.coords:\n",
    "                if coord not in ['lat','lon']:\n",
    "                    ds_new = ds_new.drop(coord)\n",
    "            \n",
    "            ds_new = ds_new.expand_dims({'ensemble': np.array([ds_new.attrs['name']])}, 0)\n",
    "            \n",
    "            ds_new.attrs['mip_id'] = mip_id\n",
    "            \n",
    "            coarsen_dict = {'lat': coarsen_size, 'lon': coarsen_size}\n",
    "            ds_new = ds_new.coarsen(coarsen_dict, boundary='exact').mean()\n",
    "            \n",
    "            ds_dict[mip_id][varname][key] = ds_new  # add this to the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmip6hack-multigen",
   "language": "python",
   "name": "cmip6hack-multigen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
