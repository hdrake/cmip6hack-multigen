{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Pre-processing model and reanalsyis data\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions for activating the Jupyter kernel for the `cmip6hack-multigen` conda environment\n",
    "\n",
    "In a Jupyterlab terminal, navigate to the `/cmip6hack-multigen/` folder and run the command:\n",
    "```bash\n",
    "source spinup_env.sh\n",
    "```\n",
    "which will create the `cmip6hack-multigen` conda environment and install it as a python kernel for jupyter.\n",
    "\n",
    "Then, switch the kernel (drop-down menu in the top right hand corner) to cmip6hack-multigen and restart the notebook.\n",
    "\n",
    "### Pre-process climate model output in GCS\n",
    "\n",
    "This notebook uses [`intake-esm`](https://intake-esm.readthedocs.io/en/latest/) to ingest and organize climate model output from various model generations and resave their time-mean fields locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xskillscore as xs\n",
    "import xesmf as xe\n",
    "from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n",
    "import intake\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# util.py is in the local directory\n",
    "# it contains code that is common across project notebooks\n",
    "# or routines that are too extensive and might otherwise clutter\n",
    "# the notebook design\n",
    "import util\n",
    "import preprocess as pp\n",
    "import qc\n",
    "\n",
    "import warnings\n",
    "\n",
    "intermediate_path = \"../data/intermediate/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = ['tas', 'pr', 'psl']\n",
    "timeslice = slice('1981', '2010')\n",
    "coarsen_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_dict = {}\n",
    "ens_dict = pp.load_ensembles(varnames, timeslice=timeslice)\n",
    "\n",
    "processed = {}\n",
    "for key in ens_dict.keys():\n",
    "    processed[key] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Extract linear trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    for key, ens in tqdm(ens_dict.items()):\n",
    "        ens_dict[key] = ens_dict[key].chunk({'ensemble': 1, 'time': -1, 'lat': 'auto', 'lon': 'auto'})\n",
    "        tas_trend = util.compute_slope(ens_dict[key]['tas'])\n",
    "        tas_trend.name = \"tas_trend\"\n",
    "        processed[key].append(tas_trend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extract seasonal climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_dict = {}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    for key, ens in tqdm(ens_dict.items()):\n",
    "        ens_dict[key] = ens_dict[key].chunk({'ensemble': 1, 'time': -1, 'lat': 'auto', 'lon': 'auto'})\n",
    "        clim, anom, ann = util.compute_derived_variables(ens)\n",
    "        rename_clim = dict([ (dv, dv+\"_clim\") for dv in clim.data_vars])\n",
    "        processed[key].append(clim.rename(rename_clim))\n",
    "        anom_dict[key] = anom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Extract internal variability (Ni√±o3.4 index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enso_dict = {}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    for key, ens in tqdm(ens_dict.items()):\n",
    "        anom = anom_dict[key]\n",
    "        enso = util.pseudo_enso(anom['tas'].chunk({'ensemble': 1, 'time': -1, 'lat': 'auto', 'lon': 'auto'}))\n",
    "        enso.name = \"enso34\"\n",
    "        processed[key].append(enso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Extracting time-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    for key, ens in tqdm(ens_dict.items()):\n",
    "        mean = ens.mean(dim=['time'], keep_attrs=True, skipna=True)\n",
    "        rename_mean = dict([ (dv, dv+\"_mean\") for dv in mean.data_vars])\n",
    "        processed[key].append(mean.rename(rename_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Save computed intermediate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in processed.keys():\n",
    "    ens = xr.merge(processed[key])\n",
    "    for data_var in ens.data_vars:\n",
    "        # Remove empty attribute that messes up to_zarr method\n",
    "        if 'intake_esm_varname' in ens[data_var].attrs:\n",
    "            del ens[data_var].attrs['intake_esm_varname']\n",
    "    \n",
    "    ens.to_zarr(intermediate_path + f\"{key}\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process observational data products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5 = pp.load_era(\"../data/raw/reanalysis/ERA5_mon_2d.nc\", timeslice=timeslice, coarsen_size=2).chunk({'time': -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    era_trend = util.compute_slope(era5['tas'])\n",
    "    era_trend.name = \"tas_trend\"\n",
    "    \n",
    "    era_clim, era_anom, era_ann = util.compute_derived_variables(era5)\n",
    "    rename_clim = dict([ (dv, dv+\"_clim\") for dv in era_clim.data_vars])\n",
    "    era_clim = era_clim.rename(rename_clim)\n",
    "    \n",
    "    era_enso = util.pseudo_enso(era_anom['tas'].chunk({'time': -1})).compute()\n",
    "    era_enso.name = \"enso34\"\n",
    "    \n",
    "    era_mean = era5.mean(dim=['time'], keep_attrs=True, skipna=True)\n",
    "    rename_mean = dict([ (dv, dv+\"_mean\") for dv in era_mean.data_vars])\n",
    "    era_mean = era_mean.rename(rename_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge([era_trend, era_clim, era_enso, era_mean]).to_zarr(intermediate_path + \"era5\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
